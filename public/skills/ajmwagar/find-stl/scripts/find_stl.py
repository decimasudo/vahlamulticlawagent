#!/usr/bin/env python3
"""find-stl

Search + fetch 3D models from Printables.

Design goals:
- deterministic CLI (search -> fetch)
- no external deps (pure Python)
- produce a local folder + manifest.json with attribution + license

Commands:
  search <query> [--limit N]
  fetch  <print_id> [--outdir DIR] [--mode all|stls]

Notes:
- Downloads use Printables GraphQL mutation getDownloadLink() to get a time-limited URL.
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import re
import sys
import time
import urllib.error
import urllib.parse
import urllib.request
import zipfile
from typing import Any, Dict, List, Optional, Tuple

PRINTABLES_GQL = "https://api.printables.com/graphql/"


def http_json(url: str, payload: Dict[str, Any], timeout: int = 30) -> Dict[str, Any]:
    data = json.dumps(payload).encode("utf-8")
    # Printables is picky about automation. Spoof a normal browser-ish request.
    req = urllib.request.Request(
        url,
        data=data,
        headers={
            "content-type": "application/json",
            "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "origin": "https://www.printables.com",
            "referer": "https://www.printables.com/",
        },
    )
    with urllib.request.urlopen(req, timeout=timeout) as r:
        return json.loads(r.read().decode("utf-8"))


def gql(query: str, variables: Dict[str, Any]) -> Dict[str, Any]:
    out = http_json(PRINTABLES_GQL, {"query": query, "variables": variables})
    if "errors" in out and out["errors"]:
        raise RuntimeError(f"GraphQL errors: {out['errors']}")
    return out["data"]


def printables_search(query_text: str, limit: int = 10, offset: int = 0) -> Dict[str, Any]:
    q = (
        "query($q:String!,$limit:Int!,$offset:Int!){"
        "searchPrints2(query:$q,limit:$limit,offset:$offset){"
        "totalCount items{ id name slug downloadCount likesCount filesCount user{handle} }"
        "}}"
    )
    return gql(q, {"q": query_text, "limit": int(limit), "offset": int(offset)})["searchPrints2"]


def printables_get_print(print_id: str) -> Dict[str, Any]:
    q = (
        "query($id:ID!){"
        "print(id:$id){"
        "id name slug summary description downloadCount likesCount filesCount "
        "user{handle} license{id disallowRemixing} excludeCommercialUsage "
        "stls{ id name fileSize folder note } "
        "downloadPacks{ id fileSize fileType }"
        "}}"
    )
    return gql(q, {"id": str(print_id)})["print"]


def printables_get_download_link(print_id: str, file_type: str, ids: List[str]) -> str:
    # file_type: stl | pack
    m = (
        "mutation($printId:ID!,$ids:[ID!]!,$ft:DownloadFileTypeEnum!){"
        "getDownloadLink(printId:$printId, source:model_detail, files:[{fileType:$ft, ids:$ids}])"
        "{ok errors{field messages code} output{link ttl}}"
        "}"
    )
    data = http_json(
        PRINTABLES_GQL,
        {
            "query": m,
            "variables": {"printId": str(print_id), "ids": [str(i) for i in ids], "ft": file_type},
        },
    )["data"]["getDownloadLink"]
    if not data.get("ok"):
        raise RuntimeError(f"getDownloadLink failed: {data.get('errors')}")
    return data["output"]["link"]


def sha256_file(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def download_file(url: str, out_path: str, timeout: int = 60) -> None:
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    req = urllib.request.Request(url, headers={"user-agent": "Mozilla/5.0"})
    with urllib.request.urlopen(req, timeout=timeout) as r:
        with open(out_path, "wb") as f:
            while True:
                b = r.read(1024 * 1024)
                if not b:
                    break
                f.write(b)


def safe_slug(s: str) -> str:
    s = s.strip().lower()
    s = re.sub(r"[^a-z0-9]+", "-", s)
    s = re.sub(r"-+", "-", s).strip("-")
    return s or "model"


def cmd_search(args: argparse.Namespace) -> int:
    res = printables_search(args.query, limit=args.limit, offset=0)
    items = res.get("items") or []

    # Pretty print + JSON line for chaining.
    print(f"Printables results for: {args.query}")
    for i, it in enumerate(items, 1):
        url = f"https://www.printables.com/model/{it['id']}-{it['slug']}"
        print(
            f"{i}) {it['name']} â€” id={it['id']} by @{it['user']['handle']} "
            f"downloads={it['downloadCount']} likes={it['likesCount']} files={it['filesCount']}\n   {url}"
        )

    if args.json:
        print(json.dumps({"query": args.query, "results": items}, indent=2))

    return 0


def cmd_fetch(args: argparse.Namespace) -> int:
    p = printables_get_print(str(args.print_id))
    slug = safe_slug(p.get("slug") or p.get("name") or str(args.print_id))
    base_dir = os.path.join(args.outdir, f"printables-{p['id']}-{slug}")
    os.makedirs(base_dir, exist_ok=True)

    source_url = f"https://www.printables.com/model/{p['id']}-{p['slug']}"

    downloaded: List[Dict[str, Any]] = []

    # Prefer pack download (zip) when present.
    packs = p.get("downloadPacks") or []

    if args.mode == "all" and packs:
        # pick MODEL_FILES pack if present
        pack_id = None
        for pk in packs:
            if pk.get("fileType") == "MODEL_FILES":
                pack_id = pk.get("id")
                break
        if pack_id is None:
            pack_id = packs[0].get("id")

        link = printables_get_download_link(p["id"], "pack", [str(pack_id)])
        zip_path = os.path.join(base_dir, f"model-files-{pack_id}.zip")
        download_file(link, zip_path)
        downloaded.append({"kind": "pack", "id": str(pack_id), "url": link, "path": zip_path, "sha256": sha256_file(zip_path)})

        # Extract
        extract_dir = os.path.join(base_dir, "files")
        os.makedirs(extract_dir, exist_ok=True)
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall(extract_dir)

    else:
        # Download individual stl/3mf files via getDownloadLink
        stls = p.get("stls") or []
        if not stls:
            raise RuntimeError("No model files (stls/3mf) listed for this print.")

        for fobj in stls:
            fid = str(fobj["id"])
            name = fobj.get("name") or f"file-{fid}"
            link = printables_get_download_link(p["id"], "stl", [fid])
            out_path = os.path.join(base_dir, "files", name)
            download_file(link, out_path)
            downloaded.append(
                {
                    "kind": "file",
                    "id": fid,
                    "name": name,
                    "url": link,
                    "path": out_path,
                    "sha256": sha256_file(out_path),
                    "fileSize": fobj.get("fileSize"),
                }
            )

    manifest = {
        "source": "printables",
        "source_url": source_url,
        "print": {
            "id": p.get("id"),
            "name": p.get("name"),
            "slug": p.get("slug"),
            "author": p.get("user", {}).get("handle"),
            "license_id": (p.get("license") or {}).get("id"),
            "disallow_remixing": (p.get("license") or {}).get("disallowRemixing"),
            "exclude_commercial_usage": p.get("excludeCommercialUsage"),
            "downloadCount": p.get("downloadCount"),
            "likesCount": p.get("likesCount"),
            "filesCount": p.get("filesCount"),
        },
        "downloaded": downloaded,
        "fetched_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    }

    manifest_path = os.path.join(base_dir, "manifest.json")
    with open(manifest_path, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2)

    print(base_dir)
    print(manifest_path)
    return 0


def main(argv: List[str]) -> int:
    ap = argparse.ArgumentParser(prog="find_stl")
    sub = ap.add_subparsers(dest="cmd", required=True)

    ap_s = sub.add_parser("search", help="search Printables")
    ap_s.add_argument("query")
    ap_s.add_argument("--limit", type=int, default=10)
    ap_s.add_argument("--json", action="store_true", help="also emit JSON")
    ap_s.set_defaults(func=cmd_search)

    ap_f = sub.add_parser("fetch", help="download a Printables model")
    ap_f.add_argument("print_id")
    ap_f.add_argument("--outdir", default=os.path.expanduser("~/models/incoming"))
    ap_f.add_argument("--mode", choices=["all", "stls"], default="all")
    ap_f.set_defaults(func=cmd_fetch)

    args = ap.parse_args(argv)
    return int(args.func(args))


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
