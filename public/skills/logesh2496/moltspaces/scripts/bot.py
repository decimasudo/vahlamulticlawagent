#
# Copyright (c) 2024â€“2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""Moltspaces Voice Bot - OpenClaw Skill.

A voice AI bot for joining real-time conversations at moltspaces.com.

Required AI services:
- ElevenLabs (Speech-to-Text and Text-to-Speech)
- OpenAI (LLM)
- Daily (WebRTC transport)

Run the bot using::

    uv run bot.py --room <room_name>
"""

import os
import argparse
import asyncio
import sys

# Check Python version compatibility
if sys.version_info < (3, 10):
    print("âŒ Error: Python 3.10 or higher is required.")
    sys.exit(1)

from dotenv import load_dotenv
from loguru import logger

print("ðŸš€ Starting Moltspaces bot...")
print("â³ Loading models and imports (20 seconds, first run only)\n")

# Monkey-patch ONNX Runtime to auto-specify providers before importing pipecat
# This fixes compatibility with pipecat which doesn't set providers parameter
try:
    import onnxruntime as ort
    _original_init = ort.InferenceSession.__init__
    
    def _patched_init(self, model_path, sess_options=None, providers=None, **kwargs):
        # If providers not specified, default to CPU
        if providers is None:
            providers = ['CPUExecutionProvider']
        return _original_init(self, model_path, sess_options=sess_options, providers=providers, **kwargs)
    
    ort.InferenceSession.__init__ = _patched_init
    logger.info("âœ… ONNX Runtime patched for CPU provider compatibility")
except Exception as e:
    logger.warning(f"âš ï¸  Could not patch ONNX Runtime: {e}")

logger.info("Loading Local Smart Turn Analyzer V3...")
from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3

logger.info("âœ… Local Smart Turn Analyzer V3 loaded")
logger.info("Loading Silero VAD model...")
from pipecat.audio.vad.silero import SileroVADAnalyzer

logger.info("âœ… Silero VAD model loaded")

from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import Frame, LLMRunFrame, SystemFrame, TranscriptionFrame
from pipecat.processors.frame_processor import FrameProcessor

logger.info("Loading pipeline components...")
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair

from pipecat.processors.frameworks.rtvi import RTVIConfig, RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments, DailyRunnerArguments
from pipecat.services.elevenlabs.stt import ElevenLabsRealtimeSTTService
from pipecat.services.elevenlabs.tts import ElevenLabsTTSService
from pipecat.services.openai.llm import OpenAILLMService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.daily.transport import DailyParams, DailyTransport

logger.info("âœ… All components loaded successfully!")

load_dotenv(override=True)

# Global shutdown event for graceful termination
# OpenClaw can set this event to stop the bot cleanly
shutdown_event = asyncio.Event()


async def run_bot(transport: BaseTransport, runner_args: RunnerArguments, agent_name: str):
    logger.info(f"Starting bot as: {agent_name}")

    stt = ElevenLabsRealtimeSTTService(api_key=os.getenv("ELEVENLABS_API_KEY"))

    # Load voice ID from environment, default to Zaal
    voice_id = os.getenv("ELEVENLABS_VOICE_ID", "4tRn1lSkEn13EVTuqb0g")
    logger.info(f"Using ElevenLabs voice ID: {voice_id}")
    
    tts = ElevenLabsTTSService(
        api_key=os.getenv("ELEVENLABS_API_KEY", ""),
        voice_id=voice_id,
    )

    llm = OpenAILLMService(api_key=os.getenv("OPENAI_API_KEY"))

    messages = [
        {
            "role": "system",
            "content": f"""You are {agent_name}, a friendly and engaging AI voice assistant in a Moltspaces audio room.

## Your Role
- Participate in natural conversations
- Keep discussions flowing smoothly and ensure everyone feels included
- Listen to the conversation and respond naturally during silence

## Response Protocol
- Keep ALL responses VERY brief and concise (1-2 sentences max)
- Be warm, welcoming, and conversational
- Ask open-ended questions to encourage discussion
- Only speak during silence - wait for natural pauses in the conversation

## Guidelines
- When someone joins, greet them warmly by name
- Encourage quieter participants to share their thoughts
- Summarize key points briefly when helpful
- Keep the energy positive and inclusive
- If multiple agents are present, be respectful and coordinate responses
- Wait for appropriate silence before responding""",
        },
    ]

    context = LLMContext(messages)
    context_aggregator = LLMContextAggregatorPair(context)

    rtvi = RTVIProcessor(config=RTVIConfig(config=[]))

    # Wake filter removed - bot responds during natural silence in conversation
    # Turn-taking is managed by LocalSmartTurnAnalyzerV3 and VAD

    pipeline = Pipeline(
        [
            transport.input(),  # Transport user input
            rtvi,  # RTVI processor
            stt,
            context_aggregator.user(),  # User responses
            llm,  # LLM
            tts,  # TTS
            transport.output(),  # Transport bot output
            context_aggregator.assistant(),  # Assistant spoken responses
        ]
    )

    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            allow_interruptions=True,  # Stop bot audio when user speaks
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        observers=[RTVIObserver(rtvi)],
    )

    @transport.event_handler("on_participant_joined")
    async def on_participant_joined(transport, participant):
        # Safely get participant name with fallback
        participant_info = participant.get("info", {})
        participant_name = participant_info.get("userName") or participant_info.get("name") or "Guest"
        participant_id = participant["id"]
        
        logger.info(f"Participant joined: {participant_name} (ID: {participant_id})")
        await transport.capture_participant_transcription(participant_id)
        # Kick off the conversation with personalized greeting.
        messages.append({"role": "system", "content": f"Greet {participant_name} by name."})
        await task.queue_frames([LLMRunFrame()])

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info(f"Client disconnected")
        await task.cancel()

    # Monitor shutdown event for OpenClaw
    async def monitor_shutdown():
        """Watch for shutdown_event and cancel task when triggered."""
        await shutdown_event.wait()
        logger.info("ðŸ›‘ Shutdown signal received, stopping bot...")
        await task.cancel()

    runner = PipelineRunner(handle_sigint=runner_args.handle_sigint)

    # Run bot with shutdown monitoring
    try:
        shutdown_monitor = asyncio.create_task(monitor_shutdown())
        await runner.run(task)
    except asyncio.CancelledError:
        logger.info("âœ… Bot stopped gracefully")
    finally:
        # Clean up shutdown monitor
        if not shutdown_monitor.done():
            shutdown_monitor.cancel()


async def main(room_url: str, token: str):
    """Main entry point.
    
    Args:
        room_url: The Daily room URL to connect to.
        token: The Daily room token.
    """
    
    # Load agent identity from environment
    # MOLT_AGENT_NAME: Friendly name for wake phrases and display (e.g., "Sarah", "Marcus")
    # MOLT_AGENT_ID: Technical ID for API authentication
    agent_display_name = os.getenv("MOLT_AGENT_NAME") or os.getenv("MOLT_AGENT_ID", "Moltspaces Agent")
    logger.info(f"ðŸ¤– Bot will join as: {agent_display_name}")
    logger.info(f"ï¿½ Connecting to room: {room_url}")

    # Create transport and join room
    logger.info(f"ðŸš€ Joining Daily room...")
    transport = DailyTransport(
        room_url,
        token,
        agent_display_name,  # Use MOLT_AGENT_NAME as bot display name
        DailyParams(
            audio_in_enabled=True,
            audio_out_enabled=True,
            vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
            turn_analyzer=LocalSmartTurnAnalyzerV3(),
            enable_prejoin_ui=True,
        ),
    )
    
    runner_args = RunnerArguments()
    await run_bot(transport, runner_args, agent_display_name)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Moltspaces Voice Bot",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  uv run bot.py --url https://your-domain.daily.co/room --token <token>
        """
    )
    
    parser.add_argument("-u", "--url", type=str, required=True, help="Full Daily room URL")
    parser.add_argument("-t", "--token", type=str, required=True, help="Daily room token")
    
    config = parser.parse_args()
    
    asyncio.run(main(room_url=config.url, token=config.token))

